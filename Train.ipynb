{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 0. Import Libraries"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from __future__ import print_function\r\n",
    "import tensorflow as tf\r\n",
    "import keras\r\n",
    "from keras.preprocessing.image import ImageDataGenerator\r\n",
    "from keras.models import Sequential\r\n",
    "from keras.layers import Dense,Dropout,Activation,Flatten,BatchNormalization\r\n",
    "from keras.layers import Conv2D,MaxPooling2D\r\n",
    "import os"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Read the the dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "num_classes=2\r\n",
    "img_rows,img_cols=48,48\r\n",
    "batch_size=32\r\n",
    "\r\n",
    "train_data_dir='data_set/train'\r\n",
    "validation_data_dir='data_set/validation'\r\n",
    "\r\n",
    "train_datagen = ImageDataGenerator(\r\n",
    "\t\t\t\t\trescale=1./255,\r\n",
    "\t\t\t\t\trotation_range=30,\r\n",
    "\t\t\t\t\tshear_range=0.3,\r\n",
    "\t\t\t\t\tzoom_range=0.3,\r\n",
    "\t\t\t\t\twidth_shift_range=0.4,\r\n",
    "\t\t\t\t\theight_shift_range=0.4,\r\n",
    "\t\t\t\t\thorizontal_flip=True,\r\n",
    "\t\t\t\t\tfill_mode='nearest')\r\n",
    "\r\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\r\n",
    "\r\n",
    "train_generator = train_datagen.flow_from_directory(\r\n",
    "\t\t\t\t\ttrain_data_dir,\r\n",
    "\t\t\t\t\tcolor_mode='grayscale',\r\n",
    "\t\t\t\t\ttarget_size=(img_rows,img_cols),\r\n",
    "\t\t\t\t\tbatch_size=batch_size,\r\n",
    "\t\t\t\t\tclass_mode='categorical',\r\n",
    "\t\t\t\t\tshuffle=True)\r\n",
    "\t\t\t\t\t\r\n",
    "validation_generator = validation_datagen.flow_from_directory(\r\n",
    "\t\t\t\t\t\t\tvalidation_data_dir,\r\n",
    "\t\t\t\t\t\t\tcolor_mode='grayscale',\r\n",
    "\t\t\t\t\t\t\ttarget_size=(img_rows,img_cols),\r\n",
    "\t\t\t\t\t\t\tbatch_size=batch_size,\r\n",
    "\t\t\t\t\t\t\tclass_mode='categorical',\r\n",
    "\t\t\t\t\t\t\tshuffle=True)\r\n",
    "\r\n",
    "model = Sequential()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Fit the model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Block-1\r\n",
    "\r\n",
    "model.add(Conv2D(32,(3,3),padding='same',kernel_initializer='he_normal',input_shape=(img_rows,img_cols,1)))\r\n",
    "model.add(Activation('elu'))\r\n",
    "model.add(BatchNormalization())\r\n",
    "model.add(Conv2D(32,(3,3),padding='same',kernel_initializer='he_normal',input_shape=(img_rows,img_cols,1)))\r\n",
    "model.add(Activation('elu'))\r\n",
    "model.add(BatchNormalization())\r\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\r\n",
    "model.add(Dropout(0.2))\r\n",
    "\r\n",
    "#Block-2 \r\n",
    "\r\n",
    "model.add(Conv2D(64,(3,3),padding='same',kernel_initializer='he_normal'))\r\n",
    "model.add(Activation('elu'))\r\n",
    "model.add(BatchNormalization())\r\n",
    "model.add(Conv2D(64,(3,3),padding='same',kernel_initializer='he_normal'))\r\n",
    "model.add(Activation('elu'))\r\n",
    "model.add(BatchNormalization())\r\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\r\n",
    "model.add(Dropout(0.2))\r\n",
    "\r\n",
    "#Block-3\r\n",
    "\r\n",
    "model.add(Conv2D(128,(3,3),padding='same',kernel_initializer='he_normal'))\r\n",
    "model.add(Activation('elu'))\r\n",
    "model.add(BatchNormalization())\r\n",
    "model.add(Conv2D(128,(3,3),padding='same',kernel_initializer='he_normal'))\r\n",
    "model.add(Activation('elu'))\r\n",
    "model.add(BatchNormalization())\r\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\r\n",
    "model.add(Dropout(0.2))\r\n",
    "\r\n",
    "#Block-4 \r\n",
    "\r\n",
    "model.add(Conv2D(256,(3,3),padding='same',kernel_initializer='he_normal'))\r\n",
    "model.add(Activation('elu'))\r\n",
    "model.add(BatchNormalization())\r\n",
    "model.add(Conv2D(256,(3,3),padding='same',kernel_initializer='he_normal'))\r\n",
    "model.add(Activation('elu'))\r\n",
    "model.add(BatchNormalization())\r\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\r\n",
    "model.add(Dropout(0.2))\r\n",
    "\r\n",
    "#Block-5\r\n",
    "\r\n",
    "model.add(Flatten())\r\n",
    "model.add(Dense(64,kernel_initializer='he_normal'))\r\n",
    "model.add(Activation('elu'))\r\n",
    "model.add(BatchNormalization())\r\n",
    "model.add(Dropout(0.5))\r\n",
    "\r\n",
    "#Block-6\r\n",
    "\r\n",
    "model.add(Dense(64,kernel_initializer='he_normal'))\r\n",
    "model.add(Activation('elu'))\r\n",
    "model.add(BatchNormalization())\r\n",
    "model.add(Dropout(0.5))\r\n",
    "\r\n",
    "#Block-7\r\n",
    "\r\n",
    "model.add(Dense(num_classes,kernel_initializer='he_normal'))\r\n",
    "model.add(Activation('softmax'))\r\n",
    "\r\n",
    "print(model.summary())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Train the model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\r\n",
    "from tensorflow.keras.optimizers import SGD\r\n",
    "from tensorflow.keras.optimizers import Adam\r\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\r\n",
    "from time import time\r\n",
    "\r\n",
    "# checkPointName = 'EmotionDetectionModel.h5'\r\n",
    "#quick fix to increment the file if it exists\r\n",
    "counter = 0\r\n",
    "filename = \"EmotionDetectionModel{}.h5\"\r\n",
    "while os.path.isfile(filename.format(counter)):\r\n",
    "    counter += 1\r\n",
    "checkPointName = filename.format(counter)\r\n",
    "#quick fix to increment the file if it exists\r\n",
    "\r\n",
    "checkpoint = ModelCheckpoint(checkPointName,\r\n",
    "                             monitor='val_loss',\r\n",
    "                             mode='min',\r\n",
    "                             verbose=1)\r\n",
    "\r\n",
    "earlystop = EarlyStopping(monitor='accuracy',\r\n",
    "                          min_delta=0,\r\n",
    "                          patience=5000,\r\n",
    "                          verbose=1,\r\n",
    "                          restore_best_weights=True\r\n",
    "                          )\r\n",
    "\r\n",
    "reduce_lr = ReduceLROnPlateau(monitor='accuracy',\r\n",
    "                              factor=0.2,\r\n",
    "                              patience=5000,\r\n",
    "                              verbose=1,\r\n",
    "                              min_delta=0.0001)\r\n",
    "\r\n",
    "# Create a TensorBoard instance with the path to the logs directory\r\n",
    "tensorboard = TensorBoard(log_dir='logs/{}'.format(time()))\r\n",
    "\r\n",
    "callbacks = [earlystop,checkpoint,reduce_lr, tensorboard]\r\n",
    "''', tensorboard'''\r\n",
    "\r\n",
    "model.compile(loss='categorical_crossentropy',\r\n",
    "              optimizer = Adam(lr=0.001),\r\n",
    "              metrics=['accuracy'])\r\n",
    "\r\n",
    "nb_train_samples = 43\r\n",
    "nb_validation_samples = 10\r\n",
    "epochs=100\r\n",
    "\r\n",
    "history=model.fit_generator(\r\n",
    "                train_generator,\r\n",
    "                steps_per_epoch=nb_train_samples//batch_size,\r\n",
    "                epochs=epochs,\r\n",
    "                callbacks=callbacks,\r\n",
    "                validation_data=validation_generator,\r\n",
    "                validation_steps=nb_validation_samples//batch_size)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}